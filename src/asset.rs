//! Media type-agnostic asset handling
//!
//! This module provides a unified API for working with media files
//! without needing to know the specific media type.

use crate::{
    containers::ContainerKind, detect_container, error::Result, get_handler, structure::Structure,
    Updates,
};
use std::fs::File;
use std::io::{Read, Seek, SeekFrom, Write};
use std::path::Path;

// Handler enum is generated by register_formats! macro in formats/mod.rs
use crate::Handler;

/// A media asset that automatically detects and handles its media type
///
/// # Example
///
/// ```no_run
/// use asset_io::{Asset, Updates};
///
/// # fn main() -> asset_io::Result<()> {
/// // Open any supported media file - media type is auto-detected
/// let mut asset = Asset::open("image.jpg")?;
///
/// // Read metadata
/// if let Some(xmp) = asset.xmp()? {
///     println!("XMP: {} bytes", xmp.len());
/// }
///
/// // Modify and write
/// let updates = Updates::new().set_xmp(b"<new>metadata</new>".to_vec());
/// asset.write_to("output.jpg", &updates)?;
/// # Ok(())
/// # }
/// ```
pub struct Asset<R: Read + Seek> {
    source: R,
    structure: Structure,
    handler: Handler,
}

// Handler enum and implementation are generated by register_formats! macro in lib.rs

impl Asset<File> {
    /// Open a media file from a path
    ///
    /// The media type is automatically detected from the file header.
    pub fn open<P: AsRef<Path>>(path: P) -> Result<Self> {
        let file = File::open(path)?;
        Self::from_file(file)
    }

    /// Create an Asset from an owned File
    pub fn from_file(mut file: File) -> Result<Self> {
        file.seek(SeekFrom::Start(0))?;
        let container = detect_container(&mut file)?;
        file.seek(SeekFrom::Start(0))?;

        let handler = get_handler(container)?;
        let structure = handler.parse(&mut file)?;

        Ok(Asset {
            source: file,
            structure,
            handler,
        })
    }

    /// Open a media file with memory mapping for zero-copy operations
    ///
    /// This method applies best practices for memory-mapped file access:
    /// - Opens the file read-only
    /// - Acquires an advisory shared lock (prevents cooperative writers)
    /// - Verifies file size stability during setup
    /// - Creates memory map for zero-copy access
    ///
    /// # Safety
    ///
    /// Memory mapping is inherently unsafe because:
    /// - **Advisory locks are cooperative**: They only prevent other processes
    ///   that also acquire locks. Non-cooperative processes can still modify the file.
    /// - **File modifications cause undefined behavior**: If the file is modified
    ///   by any process while mapped, reading from the map may cause crashes or
    ///   data corruption.
    ///
    /// Only use this method when:
    /// - You control all processes that access the file, OR
    /// - The file is read-only at the OS level, OR
    /// - You have external guarantees the file won't be modified
    ///
    /// # Performance
    ///
    /// Memory-mapped access provides:
    /// - Zero-copy reads (no buffer allocations)
    /// - OS-level page caching (shared across processes)
    /// - Significant speedup for large files (10-100x for hashing)
    ///
    /// # Example
    ///
    /// ```no_run
    /// use asset_io::Asset;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// // Open with memory mapping (advisory lock acquired)
    /// let mut asset = unsafe { Asset::open_with_mmap("image.jpg")? };
    ///
    /// // Zero-copy access for hashing
    /// let ranges = asset.structure().hashable_ranges(&["jumbf"]);
    /// for range in ranges {
    ///     if let Some(slice) = asset.structure().get_mmap_slice(range) {
    ///         // Process slice directly from memory map (zero-copy!)
    ///     }
    /// }
    /// # Ok(())
    /// # }
    /// ```
    #[cfg(feature = "memory-mapped")]
    pub unsafe fn open_with_mmap<P: AsRef<Path>>(path: P) -> Result<Self> {
        #[allow(unused_imports)] // FileExt trait is used for lock_shared() method
        use fs2::FileExt;

        let path = path.as_ref();

        // Open read-only (best we can do for safety)
        let file = std::fs::OpenOptions::new()
            .read(true)
            .write(false)
            .open(path)?;

        // Get initial file metadata
        let metadata = file.metadata()?;
        let initial_size = metadata.len();

        // Acquire advisory shared lock (allows multiple concurrent readers)
        // This prevents cooperative writers but doesn't guarantee safety
        file.lock_shared()?;

        // Verify file size hasn't changed (basic race condition check)
        let current_size = file.metadata()?.len();
        if current_size != initial_size {
            file.unlock()?;
            return Err(crate::Error::InvalidFormat(
                "File size changed during open (file may be unstable)".into(),
            ));
        }

        // Create memory map (unsafe operation)
        let mmap = memmap2::Mmap::map(&file)?;

        // Create asset from file
        // Note: Advisory lock remains held as long as file handle exists
        let mut asset = Self::from_file(file)?;

        // Attach memory map for zero-copy access
        asset.structure.set_mmap(mmap);

        Ok(asset)
    }
}

impl<R: Read + Seek> Asset<R> {
    /// Create an Asset from a source (media type auto-detected)
    ///
    /// The media type is detected by reading the header. The source will be
    /// seeked to position 0 before detection.
    ///
    /// # Example
    ///
    /// ```no_run
    /// use asset_io::Asset;
    /// use std::io::Cursor;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let jpeg_data = std::fs::read("image.jpg")?;
    /// let cursor = Cursor::new(jpeg_data);
    ///
    /// // Media type auto-detected from header
    /// let mut asset = Asset::from_source(cursor)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn from_source(mut source: R) -> Result<Self> {
        source.seek(SeekFrom::Start(0))?;
        let container = detect_container(&mut source)?;
        source.seek(SeekFrom::Start(0))?;

        let handler = get_handler(container)?;
        let structure = handler.parse(&mut source)?;

        Ok(Asset {
            source,
            structure,
            handler,
        })
    }

    /// Get the detected format
    pub fn container(&self) -> ContainerKind {
        self.structure.container
    }

    /// Get the media type of this asset
    pub fn media_type(&self) -> crate::MediaType {
        self.structure.media_type
    }

    /// Get XMP metadata (loads lazily, assembles extended parts if present)
    pub fn xmp(&mut self) -> Result<Option<Vec<u8>>> {
        self.handler.read_xmp(&self.structure, &mut self.source)
    }

    /// Get JUMBF data (loads and assembles lazily)
    pub fn jumbf(&mut self) -> Result<Option<Vec<u8>>> {
        self.handler
            .read_jumbf(&self.structure, &mut self.source)
    }

    /// Extract an embedded thumbnail if available
    ///
    /// Many image formats include pre-rendered thumbnails for quick preview:
    /// - JPEG: EXIF thumbnail (typically 160x120)
    /// - PNG: EXIF thumbnail (if eXIf chunk present)
    ///
    /// This is the fastest way to get a thumbnail if available - no decoding needed!
    ///
    /// Returns `None` if:
    /// - No embedded thumbnail exists in the file
    /// - The format doesn't support embedded thumbnails
    /// - The `exif` feature is not enabled (required for thumbnail extraction)
    ///
    /// # Example
    ///
    /// ```no_run
    /// use asset_io::Asset;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let mut asset = Asset::open("photo.jpg")?;
    ///
    /// // Try embedded thumbnail first (fastest - no decoding!)
    /// if let Some(thumb) = asset.read_embedded_thumbnail()? {
    ///     println!("Found {:?} thumbnail, {} bytes", thumb.format, thumb.data.len());
    ///     if let (Some(w), Some(h)) = (thumb.width, thumb.height) {
    ///         println!("Dimensions: {}x{}", w, h);
    ///     }
    ///     // thumb.data contains the raw JPEG/PNG bytes
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_embedded_thumbnail(&mut self) -> Result<Option<crate::Thumbnail>> {
        #[cfg(feature = "exif")]
        {
            use std::io::SeekFrom;
            
            // Get thumbnail location info
            let info = self.handler
                .read_embedded_thumbnail_info(&self.structure, &mut self.source)?;
            
            match info {
                Some(info) => {
                    // Read the actual thumbnail data
                    self.source.seek(SeekFrom::Start(info.offset))?;
                    let mut data = vec![0u8; info.size as usize];
                    self.source.read_exact(&mut data)?;
                    
                    Ok(Some(crate::Thumbnail {
                        data,
                        format: info.format,
                        width: info.width,
                        height: info.height,
                    }))
                }
                None => Ok(None),
            }
        }

        #[cfg(not(feature = "exif"))]
        {
            // Return None when exif feature is not enabled
            Ok(None)
        }
    }

    /// Get basic EXIF metadata (Make, Model, DateTime, etc.)
    ///
    /// Returns parsed EXIF information if the file contains EXIF data.
    /// This is a lightweight extraction of common EXIF fields.
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::Asset;
    ///
    /// let mut asset = Asset::open("photo.jpg")?;
    /// if let Some(info) = asset.exif_info()? {
    ///     println!("Camera: {} {}", info.make.unwrap_or_default(), info.model.unwrap_or_default());
    ///     if let Some(dt) = info.date_time_original {
    ///         println!("Taken: {}", dt);
    ///     }
    /// }
    /// # Ok::<(), asset_io::Error>(())
    /// ```
    #[cfg(feature = "exif")]
    pub fn exif_info(&mut self) -> Result<Option<crate::tiff::ExifInfo>> {
        // Delegate to container-specific handler
        self.handler.read_exif_info(&self.structure, &mut self.source)
    }

    /// Get the file structure
    pub fn structure(&self) -> &Structure {
        &self.structure
    }

    /// Get mutable access to the file structure
    ///
    /// This is useful for advanced operations like attaching memory maps
    #[cfg(feature = "memory-mapped")]
    pub fn structure_mut(&mut self) -> &mut Structure {
        &mut self.structure
    }

    /// Get a mutable reference to the source
    ///
    /// This allows advanced operations like chunked reading for hashing
    pub fn source_mut(&mut self) -> &mut R {
        &mut self.source
    }

    /// Create a chunked reader for a byte range (convenience method)
    pub fn read_range_chunked(
        &mut self,
        range: crate::ByteRange,
        chunk_size: usize,
    ) -> Result<crate::ChunkedSegmentReader<std::io::Take<&mut R>>> {
        self.structure
            .read_range_chunked(&mut self.source, range, chunk_size)
    }

    /// Create a chunked reader for a segment (convenience method)
    pub fn read_segment_chunked(
        &mut self,
        segment_index: usize,
        chunk_size: usize,
    ) -> Result<crate::ChunkedSegmentReader<std::io::Take<&mut R>>> {
        self.structure
            .read_segment_chunked(&mut self.source, segment_index, chunk_size)
    }

    /// Process the asset's data with exclusions (read-side of write_with_processing)
    ///
    /// This is the read equivalent of `write_with_processing()`. It streams through
    /// the asset's data, calling the processor for each chunk while respecting
    /// the exclusion settings in `updates.processing`.
    ///
    /// Use this for:
    /// - Hashing an existing file
    /// - Validating data integrity
    /// - Calculating statistics
    /// - Any non-destructive processing
    ///
    /// # Example: Hash an existing file
    /// ```no_run
    /// use asset_io::{Asset, Updates, SegmentKind, ExclusionMode};
    /// use sha2::{Sha256, Digest};
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let mut asset = Asset::open("signed.jpg")?;
    ///
    /// // Configure exclusions (same options as write_with_processing)
    /// let updates = Updates::new()
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// // Process the data
    /// let mut hasher = Sha256::new();
    /// asset.read_with_processing(&updates, &mut |chunk| hasher.update(chunk))?;
    /// let hash = hasher.finalize();
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_with_processing<F>(
        &mut self,
        updates: &Updates,
        processor: &mut F,
    ) -> Result<()>
    where
        F: FnMut(&[u8]),
    {
        use crate::segment::DEFAULT_CHUNK_SIZE;
        
        let chunk_size = updates.processing.effective_chunk_size();
        let exclude_segments = &updates.processing.exclude_segments;
        let exclusion_mode = updates.processing.exclusion_mode;
        
        self.source.seek(SeekFrom::Start(0))?;
        
        // Build list of segment indices to exclude
        let excluded_indices: Vec<Option<usize>> = exclude_segments
            .iter()
            .filter_map(|kind| {
                self.structure.segments.iter().position(|s| s.is_type(*kind))
            })
            .map(Some)
            .collect();
        
        // Calculate ranges to process (everything except excluded segments)
        let mut ranges = Vec::new();
        let mut last_end = 0u64;
        
        for (idx, segment) in self.structure.segments.iter().enumerate() {
            let is_excluded = excluded_indices.contains(&Some(idx));
            
            if is_excluded {
                let loc = segment.location();
                // Determine exclusion range based on mode
                let (exclude_start, exclude_size) = if exclusion_mode == crate::ExclusionMode::DataOnly {
                    // DataOnly: exclude just the data portion (container-specific)
                    // For now, use the segment's data location
                    (loc.offset, loc.size)
                } else {
                    // EntireSegment: exclude the whole segment
                    (loc.offset, loc.size)
                };
                
                // Add range before this excluded segment
                if exclude_start > last_end {
                    ranges.push((last_end, exclude_start - last_end));
                }
                last_end = exclude_start + exclude_size;
            }
        }
        
        // Add final range after last exclusion
        if last_end < self.structure.total_size {
            ranges.push((last_end, self.structure.total_size - last_end));
        }
        
        // Process each range with overlapped I/O
        // We use double-buffering: read next chunk while processing current
        let buffer_size = chunk_size.min(DEFAULT_CHUNK_SIZE);
        
        for (offset, size) in ranges {
            self.source.seek(SeekFrom::Start(offset))?;
            let mut remaining = size;
            
            // Read first chunk
            let first_read = remaining.min(buffer_size as u64) as usize;
            let mut current_buffer = vec![0u8; first_read];
            self.source.read_exact(&mut current_buffer)?;
            remaining -= first_read as u64;
            
            // Process with double-buffering
            while remaining > 0 {
                // Prepare next buffer
                let next_read = remaining.min(buffer_size as u64) as usize;
                let mut next_buffer = vec![0u8; next_read];
                
                // Read next chunk (I/O)
                self.source.read_exact(&mut next_buffer)?;
                
                // Process current chunk (CPU) - happens after read completes
                // Note: True overlap would require threading, but for now
                // this at least structures the code for easy threading later
                processor(&current_buffer);
                
                // Swap buffers
                current_buffer = next_buffer;
                remaining -= next_read as u64;
            }
            
            // Process the last chunk
            processor(&current_buffer);
        }
        
        Ok(())
    }

    /// Read with overlapped I/O using a background processor thread
    ///
    /// This version overlaps disk I/O with processing by sending chunks
    /// to a separate thread for processing. This can provide significant
    /// speedups (1.2-1.3x) for large files when processing is CPU-intensive.
    ///
    /// Note: For small files (<1MB), the thread spawn overhead may negate benefits.
    /// For very large files, consider `parallel_hash()` or `read_chunks()` with rayon.
    ///
    /// # Example
    /// ```no_run
    /// # use asset_io::*;
    /// # fn example() -> Result<()> {
    /// # let mut asset = Asset::open("test.jpg")?;
    /// use sha2::{Sha256, Digest};
    /// use std::sync::{Arc, Mutex};
    ///
    /// let updates = Updates::new()
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// // Use Arc<Mutex> since processor runs in a separate thread
    /// let hasher = Arc::new(Mutex::new(Sha256::new()));
    /// let hasher_clone = hasher.clone();
    ///
    /// asset.read_with_processing_overlapped(&updates, move |chunk| {
    ///     hasher_clone.lock().unwrap().update(chunk);
    /// })?;
    ///
    /// let hash = Arc::try_unwrap(hasher)
    ///     .unwrap()
    ///     .into_inner()
    ///     .unwrap()
    ///     .finalize();
    /// # Ok(())
    /// # }
    /// ```
    pub fn read_with_processing_overlapped<F>(
        &mut self,
        updates: &Updates,
        processor: F,
    ) -> Result<()>
    where
        F: FnMut(&[u8]) + Send + 'static,
    {
        use crate::segment::DEFAULT_CHUNK_SIZE;
        use std::sync::mpsc;
        use std::thread;
        
        let chunk_size = updates.processing.effective_chunk_size().max(DEFAULT_CHUNK_SIZE);
        let exclude_segments = &updates.processing.exclude_segments;
        let exclusion_mode = updates.processing.exclusion_mode;
        
        // Calculate ranges to process (same logic as read_with_processing)
        let mut ranges = Vec::new();
        let mut last_end = 0u64;
        
        for segment in self.structure.segments.iter() {
            let is_excluded = exclude_segments.iter().any(|kind| segment.is_type(*kind));
            
            if is_excluded {
                let loc = segment.location();
                let (exclude_start, exclude_size) = if exclusion_mode == crate::ExclusionMode::DataOnly {
                    (loc.offset, loc.size)
                } else {
                    (loc.offset, loc.size)
                };
                
                if exclude_start > last_end {
                    ranges.push((last_end, exclude_start - last_end));
                }
                last_end = exclude_start + exclude_size;
            }
        }
        
        if last_end < self.structure.total_size {
            ranges.push((last_end, self.structure.total_size - last_end));
        }
        
        // Use a sync channel with capacity 2 for double-buffering
        // This lets us read the next chunk while processing the current one
        let (work_tx, work_rx) = mpsc::sync_channel::<Option<Vec<u8>>>(2);
        let (done_tx, done_rx) = mpsc::sync_channel::<()>(1);
        
        // Spawn processor thread
        let processor_handle = thread::spawn(move || {
            let mut proc = processor;
            while let Ok(Some(chunk)) = work_rx.recv() {
                proc(&chunk);
            }
            done_tx.send(()).ok();
        });
        
        // Read and send chunks in main thread
        for (offset, size) in ranges {
            self.source.seek(SeekFrom::Start(offset))?;
            let mut remaining = size;
            
            while remaining > 0 {
                let to_read = remaining.min(chunk_size as u64) as usize;
                let mut buffer = vec![0u8; to_read];
                self.source.read_exact(&mut buffer)?;
                
                // Send to processor thread (blocks if channel full - backpressure)
                if work_tx.send(Some(buffer)).is_err() {
                    break;
                }
                
                remaining -= to_read as u64;
            }
        }
        
        // Signal end of data
        work_tx.send(None).ok();
        drop(work_tx);
        
        // Wait for processor to finish
        done_rx.recv().ok();
        processor_handle.join().ok();
        
        Ok(())
    }

    /// Read the file as chunks suitable for parallel processing
    ///
    /// This returns a vector of [`ProcessingChunk`](crate::ProcessingChunk)s that can be
    /// processed in parallel using libraries like `rayon`. Each chunk contains its index,
    /// offset, data, and whether it overlaps with an exclusion range.
    ///
    /// Unlike `read_with_processing()` which streams sequentially, this method buffers
    /// the chunks so they can be processed in parallel. This trades memory for parallelism.
    ///
    /// # Example with rayon
    ///
    /// ```ignore
    /// use rayon::prelude::*;
    /// use sha2::{Sha256, Digest};
    /// use asset_io::{Asset, Updates, SegmentKind, ExclusionMode};
    ///
    /// let mut asset = Asset::open("large_video.mov")?;
    /// let updates = Updates::new()
    ///     .with_chunk_size(1024 * 1024)  // 1MB chunks
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// // Read all chunks (I/O is sequential)
    /// let chunks = asset.read_chunks(&updates)?;
    ///
    /// // Hash in parallel (CPU-bound, parallelizable)
    /// let chunk_hashes: Vec<[u8; 32]> = chunks
    ///     .par_iter()
    ///     .filter(|c| !c.excluded)
    ///     .map(|c| {
    ///         let mut h = Sha256::new();
    ///         h.update(&c.data);
    ///         h.finalize().into()
    ///     })
    ///     .collect();
    /// ```
    pub fn read_chunks(&mut self, updates: &Updates) -> Result<Vec<crate::ProcessingChunk>> {
        use crate::segment::{ByteRange, ProcessingChunk, DEFAULT_CHUNK_SIZE};
        
        let chunk_size = updates.processing.effective_chunk_size().max(DEFAULT_CHUNK_SIZE);
        let exclude_segments = &updates.processing.exclude_segments;
        let exclusion_mode = updates.processing.exclusion_mode;
        
        // Calculate exclusion ranges
        let exclusion_ranges: Vec<ByteRange> = exclude_segments
            .iter()
            .filter_map(|kind| {
                self.structure.segments.iter().find(|s| s.is_type(*kind))
            })
            .map(|segment| {
                let loc = segment.location();
                if exclusion_mode == crate::ExclusionMode::DataOnly {
                    // For DataOnly, use the data portion
                    loc
                } else {
                    // For EntireSegment, use the full segment
                    loc
                }
            })
            .collect();
        
        // Read all chunks
        let mut chunks = Vec::new();
        let mut offset = 0u64;
        let mut index = 0usize;
        
        self.source.seek(SeekFrom::Start(0))?;
        
        while offset < self.structure.total_size {
            let remaining = self.structure.total_size - offset;
            let read_size = chunk_size.min(remaining as usize);
            
            let mut buffer = vec![0u8; read_size];
            self.source.read_exact(&mut buffer)?;
            
            // Check if this chunk overlaps with any exclusion range
            let chunk_range = ByteRange::new(offset, read_size as u64);
            let excluded = exclusion_ranges.iter().any(|excl| {
                let chunk_end = chunk_range.offset + chunk_range.size;
                let excl_end = excl.offset + excl.size;
                chunk_range.offset < excl_end && chunk_end > excl.offset
            });
            
            chunks.push(ProcessingChunk::new(index, offset, buffer, excluded));
            
            offset += read_size as u64;
            index += 1;
        }
        
        Ok(chunks)
    }

    /// Hash the file in parallel using rayon
    ///
    /// This is a convenience method that reads the file as chunks, hashes them
    /// in parallel, and returns the individual chunk hashes. You can then combine
    /// these into a Merkle tree root using [`merkle_root()`](crate::merkle_root).
    ///
    /// Requires the `parallel` feature.
    ///
    /// # Example
    ///
    /// ```ignore
    /// use asset_io::{Asset, Updates, SegmentKind, ExclusionMode, merkle_root};
    /// use sha2::Sha256;
    ///
    /// let mut asset = Asset::open("large_video.mov")?;
    /// let updates = Updates::new()
    ///     .with_chunk_size(1024 * 1024)
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// let chunk_hashes = asset.parallel_hash::<Sha256>(&updates)?;
    /// let root = merkle_root::<Sha256>(&chunk_hashes);
    /// ```
    #[cfg(feature = "parallel")]
    pub fn parallel_hash<H>(&mut self, updates: &Updates) -> Result<Vec<[u8; 32]>>
    where
        H: sha2::Digest + Clone + Send + Sync + Default,
    {
        use rayon::prelude::*;
        
        let chunks = self.read_chunks(updates)?;
        
        let mut hashes: Vec<(usize, [u8; 32])> = chunks
            .par_iter()
            .filter(|c| !c.excluded)
            .map(|c| {
                let mut hasher = H::new();
                hasher.update(&c.data);
                let result = hasher.finalize();
                let mut hash = [0u8; 32];
                hash.copy_from_slice(&result[..32]);
                (c.index, hash)
            })
            .collect();
        
        // Sort by index to maintain order
        hashes.sort_by_key(|(idx, _)| *idx);
        
        Ok(hashes.into_iter().map(|(_, h)| h).collect())
    }

    /// Hash the file in parallel using memory-mapped I/O
    ///
    /// This is the fastest hashing method for large files. Each rayon worker
    /// reads its chunk directly from the memory-mapped file - no sequential
    /// I/O bottleneck, no channel coordination.
    ///
    /// Requires both `memory-mapped` and `parallel` features.
    ///
    /// # Example
    ///
    /// ```ignore
    /// use asset_io::{Asset, Updates, SegmentKind, ExclusionMode, merkle_root};
    /// use sha2::Sha256;
    ///
    /// let asset = unsafe { Asset::open_with_mmap("large_video.mov")? };
    /// let updates = Updates::new()
    ///     .with_chunk_size(1024 * 1024)
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// let chunk_hashes = asset.parallel_hash_mmap::<Sha256>(&updates)?;
    /// let root = merkle_root::<Sha256>(&chunk_hashes);
    /// ```
    #[cfg(all(feature = "memory-mapped", feature = "parallel"))]
    pub fn parallel_hash_mmap<H>(&self, updates: &Updates) -> Result<Vec<[u8; 32]>>
    where
        H: sha2::Digest + Clone + Send + Sync + Default,
    {
        use crate::segment::{ByteRange, DEFAULT_CHUNK_SIZE};
        use rayon::prelude::*;
        
        // Check if mmap is available
        if !self.structure.has_mmap() {
            return Err(crate::Error::InvalidFormat(
                "No memory map available - use open_with_mmap()".into(),
            ));
        }
        
        let chunk_size = updates.processing.effective_chunk_size().max(DEFAULT_CHUNK_SIZE);
        let exclude_segments = &updates.processing.exclude_segments;
        
        // Calculate ranges to hash (everything except excluded segments)
        let mut hash_ranges: Vec<ByteRange> = Vec::new();
        let mut last_end = 0u64;
        
        for segment in self.structure.segments.iter() {
            let is_excluded = exclude_segments.iter().any(|kind| segment.is_type(*kind));
            
            if is_excluded {
                let loc = segment.location();
                if loc.offset > last_end {
                    hash_ranges.push(ByteRange::new(last_end, loc.offset - last_end));
                }
                last_end = loc.offset + loc.size;
            }
        }
        
        if last_end < self.structure.total_size {
            hash_ranges.push(ByteRange::new(last_end, self.structure.total_size - last_end));
        }
        
        // Split ranges into chunks
        let mut chunks: Vec<(usize, ByteRange)> = Vec::new();
        let mut chunk_idx = 0;
        
        for range in hash_ranges {
            let mut offset = range.offset;
            let end = range.offset + range.size;
            
            while offset < end {
                let remaining = end - offset;
                let size = remaining.min(chunk_size as u64);
                chunks.push((chunk_idx, ByteRange::new(offset, size)));
                offset += size;
                chunk_idx += 1;
            }
        }
        
        // Hash in parallel - each thread reads directly from mmap
        let structure = &self.structure;
        let hashes: Vec<(usize, [u8; 32])> = chunks
            .par_iter()
            .map(|(idx, range)| {
                let slice = structure
                    .get_mmap_slice(*range)
                    .expect("mmap slice should exist for computed range");
                
                let mut hasher = H::new();
                hasher.update(slice);
                let result = hasher.finalize();
                let mut hash = [0u8; 32];
                hash.copy_from_slice(&result[..32]);
                (*idx, hash)
            })
            .collect();
        
        // Sort by index to maintain order (parallel collect may be unordered)
        let mut sorted = hashes;
        sorted.sort_by_key(|(idx, _)| *idx);
        
        Ok(sorted.into_iter().map(|(_, h)| h).collect())
    }

    /// Hash the asset excluding specified segments (zero-copy with mmap)
    ///
    /// **Deprecated**: Use `read_with_processing()` instead for a unified API.
    ///
    /// # Example
    /// ```no_run
    /// # use asset_io::*;
    /// # use std::fs::File;
    /// # fn example() -> Result<()> {
    /// # let file = File::open("test.jpg")?;
    /// # let mut asset = Asset::from_source(file)?;
    /// use sha2::{Sha256, Digest};
    ///
    /// let mut hasher = Sha256::new();
    /// let c2pa_idx = asset.structure().c2pa_jumbf_index();
    /// asset.hash_excluding_segments(&[c2pa_idx], &mut hasher)?;
    /// let hash = hasher.finalize();
    /// # Ok(())
    /// # }
    /// ```
    #[deprecated(since = "0.2.0", note = "Use read_with_processing() instead")]
    #[allow(deprecated)]
    pub fn hash_excluding_segments<H: std::io::Write>(
        &mut self,
        excluded_indices: &[Option<usize>],
        hasher: &mut H,
    ) -> Result<()> {
        self.structure
            .hash_excluding_segments(&mut self.source, excluded_indices, hasher)
    }

    /// Write to a writer with updates
    pub fn write<W: Write>(&mut self, writer: &mut W, updates: &Updates) -> Result<()> {
        self.source.seek(SeekFrom::Start(0))?;
        self.handler
            .write(&self.structure, &mut self.source, writer, updates)
    }

    /// Write to a writer with updates and optional data processing callback
    ///
    /// This performs a streaming write where data can be processed (e.g., hashed)
    /// chunk by chunk as it's being written. This is much more efficient than
    /// writing first and then re-reading the file to hash it.
    ///
    /// The processor callback is called for each chunk of data being written,
    /// except for segments specified in `exclude_segments`. This allows you to:
    /// - Hash the asset while writing (C2PA use case)
    /// - Calculate checksums or statistics
    /// - Validate data during write
    ///
    /// Returns the destination structure, which can be used with
    /// [`Structure::update_segment`] to perform in-place updates before
    /// finalizing the output.
    ///
    /// # Example: C2PA workflow
    /// ```no_run
    /// use asset_io::{Asset, Updates, SegmentKind, ExclusionMode};
    /// use sha2::{Sha256, Digest};
    /// use std::fs::File;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let mut asset = Asset::open("input.jpg")?;
    /// let mut output = File::create("output.jpg")?;
    ///
    /// // Prepare placeholder JUMBF with exclusion options
    /// let placeholder = vec![0u8; 20000];
    /// let updates = Updates::new()
    ///     .set_jumbf(placeholder)
    ///     .exclude_from_processing(vec![SegmentKind::Jumbf], ExclusionMode::DataOnly);
    ///
    /// // Write and hash in one pass
    /// let mut hasher = Sha256::new();
    /// let structure = asset.write_with_processing(
    ///     &mut output,
    ///     &updates,
    ///     &mut |chunk| hasher.update(chunk),
    /// )?;
    ///
    /// // Generate C2PA manifest using hash
    /// let hash = hasher.finalize();
    /// let manifest = vec![/* generate manifest with hash */];
    ///
    /// // Update JUMBF in-place before closing file
    /// structure.update_segment(&mut output, SegmentKind::Jumbf, manifest)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn write_with_processing<W, F>(
        &mut self,
        writer: &mut W,
        updates: &Updates,
        processor: &mut F,
    ) -> Result<Structure>
    where
        W: Write + Seek,
        F: FnMut(&[u8]),
    {
        // Calculate destination structure
        let dest_structure = self
            .handler
            .calculate_updated_structure(&self.structure, updates)?;

        // Use the new write_with_processor method for true single-pass I/O
        self.source.seek(SeekFrom::Start(0))?;
        self.handler.write_with_processor(
            &self.structure,
            &mut self.source,
            writer,
            updates,
            processor,
        )?;

        Ok(dest_structure)
    }
}

// In-place update methods (require Read + Write + Seek)
impl<R: Read + Write + Seek> Asset<R> {
    /// Update a segment's data in-place without restructuring the file
    ///
    /// This efficiently updates metadata by overwriting existing bytes,
    /// avoiding the need to rewrite the entire file. Useful for:
    /// - C2PA manifest updates (placeholder â†’ signed)
    /// - XMP field updates (modify single property)
    /// - EXIF field updates (change camera settings metadata)
    ///
    /// # Requirements
    /// - New data must fit within existing segment capacity
    /// - File must be opened with read+write access
    /// - Data is padded with zeros if smaller than capacity
    ///
    /// # Returns
    /// - `Ok(bytes_written)` on success
    /// - `Err` if segment not found or data too large
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::{Asset, SegmentKind};
    /// use std::fs::OpenOptions;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let file = OpenOptions::new()
    ///     .read(true)
    ///     .write(true)
    ///     .open("photo.jpg")?;
    /// let mut asset = Asset::from_source(file)?;
    ///
    /// // Update JUMBF in-place (e.g., after signing)
    /// let new_manifest = vec![/* signed manifest */];
    /// asset.update_segment_in_place(SegmentKind::Jumbf, new_manifest)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn update_segment_in_place(
        &mut self,
        kind: crate::segment::SegmentKind,
        new_data: Vec<u8>,
    ) -> Result<usize> {
        use crate::{error::Error, segment::SegmentKind};

        // Find the segment
        let segment_idx = match kind {
            SegmentKind::Jumbf => self.structure.c2pa_jumbf_index(),
            SegmentKind::Xmp => self.structure.xmp_index(),
            // EXIF not yet fully implemented in Structure
            _ => {
                return Err(Error::InvalidFormat(format!(
                    "In-place updates not supported for {:?}",
                    kind
                )))
            }
        }
        .ok_or_else(|| Error::InvalidFormat(format!("No existing {:?} segment found", kind)))?;

        let segment = &self.structure.segments[segment_idx];

        // Calculate total capacity across all ranges
        let total_capacity: u64 = segment.ranges.iter().map(|r| r.size).sum();

        // Validate size
        if new_data.len() as u64 > total_capacity {
            return Err(Error::InvalidFormat(format!(
                "New data ({} bytes) exceeds capacity ({} bytes)",
                new_data.len(),
                total_capacity
            )));
        }

        // Pad to exact capacity (preserves file structure)
        let mut padded = new_data;
        padded.resize(total_capacity as usize, 0);

        // Write across ranges
        let mut offset = 0;
        for range in &segment.ranges {
            self.source.seek(SeekFrom::Start(range.offset))?;
            let to_write = (padded.len() - offset).min(range.size as usize);
            self.source.write_all(&padded[offset..offset + to_write])?;
            offset += to_write;
            if offset >= padded.len() {
                break;
            }
        }

        self.source.flush()?;
        Ok(padded.len())
    }

    /// Get the available capacity for in-place updates of a segment type
    ///
    /// Returns `None` if no segment of that type exists.
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::{Asset, SegmentKind};
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let mut asset = Asset::open("photo.jpg")?;
    ///
    /// if let Some(capacity) = asset.segment_capacity(SegmentKind::Jumbf) {
    ///     println!("Can write up to {} bytes of JUMBF", capacity);
    /// }
    /// # Ok(())
    /// # }
    /// ```
    pub fn segment_capacity(&self, kind: crate::segment::SegmentKind) -> Option<u64> {
        use crate::segment::SegmentKind;

        let idx = match kind {
            SegmentKind::Jumbf => self.structure.c2pa_jumbf_index()?,
            SegmentKind::Xmp => self.structure.xmp_index()?,
            // EXIF not yet fully implemented in Structure
            _ => return None,
        };

        Some(
            self.structure.segments[idx]
                .ranges
                .iter()
                .map(|r| r.size)
                .sum(),
        )
    }

    /// Update C2PA JUMBF manifest in-place
    ///
    /// This is a convenience method for the common C2PA workflow where a
    /// placeholder manifest is written first, then replaced with the final
    /// signed manifest.
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::{Asset, Updates};
    /// use std::fs::OpenOptions;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// // Write placeholder
    /// let mut asset = Asset::open("input.jpg")?;
    /// let placeholder = vec![0u8; 20000]; // Reserve space
    /// asset.write_to("output.jpg", &Updates::new().set_jumbf(placeholder))?;
    ///
    /// // Sign and update in-place
    /// let final_manifest = vec![/* signed manifest */];
    /// let mut file = OpenOptions::new()
    ///     .read(true)
    ///     .write(true)
    ///     .open("output.jpg")?;
    /// let mut asset = Asset::from_source(file)?;
    /// asset.update_jumbf_in_place(final_manifest)?;
    /// # Ok(())
    /// # }
    /// ```
    pub fn update_jumbf_in_place(&mut self, new_jumbf: Vec<u8>) -> Result<usize> {
        self.update_segment_in_place(crate::segment::SegmentKind::Jumbf, new_jumbf)
    }

    /// Update XMP metadata in-place
    ///
    /// Useful for modifying XMP fields without rewriting the entire file.
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::{Asset, MiniXmp};
    /// use std::fs::OpenOptions;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let file = OpenOptions::new()
    ///     .read(true)
    ///     .write(true)
    ///     .open("photo.jpg")?;
    /// let mut asset = Asset::from_source(file)?;
    ///
    /// // Modify XMP
    /// let xmp_data = asset.xmp()?.expect("No XMP found");
    /// let xmp_str = String::from_utf8_lossy(&xmp_data).into_owned();
    /// let mini_xmp = MiniXmp::new(&xmp_str);
    /// let updated = mini_xmp.set("dc:title", "Updated Title")?;
    ///
    /// // Check if it fits
    /// if updated.as_ref().len() as u64 <= asset.xmp_capacity().unwrap_or(0) {
    ///     asset.update_xmp_in_place(updated.into_inner().into_bytes())?;  // Fast in-place update!
    /// }
    /// # Ok(())
    /// # }
    /// ```
    #[cfg(feature = "xmp")]
    pub fn update_xmp_in_place(&mut self, new_xmp: Vec<u8>) -> Result<usize> {
        self.update_segment_in_place(crate::segment::SegmentKind::Xmp, new_xmp)
    }

    /// Update EXIF metadata in-place
    ///
    /// # Example
    /// ```no_run
    /// use asset_io::Asset;
    /// use std::fs::OpenOptions;
    ///
    /// # fn main() -> asset_io::Result<()> {
    /// let mut file = OpenOptions::new()
    ///     .read(true)
    ///     .write(true)
    ///     .open("photo.jpg")?;
    /// let mut asset = Asset::from_source(file)?;
    ///
    /// // Prepare new EXIF data (must fit in existing segment capacity)
    /// let new_exif = vec![/* EXIF TIFF data */];
    /// asset.update_exif_in_place(new_exif)?;
    /// # Ok(())
    /// # }
    /// ```
    #[cfg(feature = "exif")]
    pub fn update_exif_in_place(&mut self, new_exif: Vec<u8>) -> Result<usize> {
        self.update_segment_in_place(crate::segment::SegmentKind::Exif, new_exif)
    }

    /// Get capacity for JUMBF updates
    ///
    /// Returns `None` if the file has no JUMBF segment.
    pub fn jumbf_capacity(&self) -> Option<u64> {
        self.segment_capacity(crate::segment::SegmentKind::Jumbf)
    }

    /// Get capacity for XMP updates
    ///
    /// Returns `None` if the file has no XMP segment.
    #[cfg(feature = "xmp")]
    pub fn xmp_capacity(&self) -> Option<u64> {
        self.segment_capacity(crate::segment::SegmentKind::Xmp)
    }

    /// Get capacity for EXIF updates
    ///
    /// Returns `None` if the file has no EXIF segment.
    #[cfg(feature = "exif")]
    pub fn exif_capacity(&self) -> Option<u64> {
        self.segment_capacity(crate::segment::SegmentKind::Exif)
    }
}

impl Asset<File> {
    /// Write to a new file with updates
    pub fn write_to<P: AsRef<Path>>(&mut self, path: P, updates: &Updates) -> Result<()> {
        let mut output = File::create(path)?;
        self.source.seek(SeekFrom::Start(0))?;
        self.handler
            .write(&self.structure, &mut self.source, &mut output, updates)
    }
}

/// Builder for creating assets with custom options
pub struct AssetBuilder {
    // Future: Add options like memory mapping, buffer sizes, etc.
}

impl AssetBuilder {
    /// Create a new builder
    pub fn new() -> Self {
        Self {}
    }

    /// Open an asset with the configured options
    pub fn open<P: AsRef<Path>>(self, path: P) -> Result<Asset<File>> {
        Asset::open(path)
    }
}

impl Default for AssetBuilder {
    fn default() -> Self {
        Self::new()
    }
}
